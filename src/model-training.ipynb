{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sklearn.metrics\n",
    "\n",
    "import models\n",
    "import util\n",
    "\n",
    "SEED = 2021\n",
    "np.random.seed(SEED)\n",
    "# TODO might need to set more seeds (tensorflow, ...)\n",
    "\n",
    "# Stay in top-level directory for consistency\n",
    "if '/src' in os.getcwd():\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "xtrain, ytrain, xtest, ytest, xval, yval = util.load_preg_data(sim=True, onehots=True)\n",
    "# Create binary labels\n",
    "ytrain_early, ytrain_late, ytrain_preterm = util.preg_outcome_to_binaries(ytrain)\n",
    "ytest_early, ytest_late, ytest_preterm = util.preg_outcome_to_binaries(ytest)\n",
    "yval_early, yval_late, yval_preterm = util.preg_outcome_to_binaries(yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cove/Documents/S2021/cpsc464/fair-child/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Example with the preterm outcome\n",
    "lr_preterm = models.build_logreg()\n",
    "models.fit_logreg(lr_preterm, xtrain, ytrain_preterm)\n",
    "models.save_pickle(lr_preterm, 'models/lr_preterm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695571955719557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9646    0.9737    0.9691       532\n",
      "        True     0.9744    0.9656    0.9700       552\n",
      "\n",
      "    accuracy                         0.9696      1084\n",
      "   macro avg     0.9695    0.9696    0.9696      1084\n",
      "weighted avg     0.9696    0.9696    0.9696      1084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example loading model to evaluate\n",
    "del lr_preterm\n",
    "lr_preterm = models.load_pickle('models/lr_preterm')\n",
    "print(lr_preterm.score(xtest, ytest_preterm))\n",
    "print(sklearn.metrics.classification_report(ytest_preterm, lr_preterm.predict(xtest), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.610603\n",
      "[200]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.542087\n",
      "[300]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.484359\n",
      "[400]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.435218\n",
      "[500]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.39304\n",
      "[600]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.356594\n",
      "[700]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.324925\n",
      "[800]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.297276\n",
      "[900]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.273042\n",
      "[1000]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.251728\n",
      "[1100]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.232927\n",
      "[1200]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.216301\n",
      "[1300]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.201565\n",
      "[1400]\tvalid_0's auc: 0.995474\tvalid_0's binary_logloss: 0.188479\n",
      "[1500]\tvalid_0's auc: 0.998312\tvalid_0's binary_logloss: 0.175566\n",
      "[1600]\tvalid_0's auc: 0.998447\tvalid_0's binary_logloss: 0.163965\n",
      "[1700]\tvalid_0's auc: 0.998494\tvalid_0's binary_logloss: 0.153692\n",
      "[1800]\tvalid_0's auc: 0.998494\tvalid_0's binary_logloss: 0.144475\n",
      "[1900]\tvalid_0's auc: 0.998494\tvalid_0's binary_logloss: 0.136257\n",
      "[2000]\tvalid_0's auc: 0.998494\tvalid_0's binary_logloss: 0.129008\n"
     ]
    }
   ],
   "source": [
    "# Example with the preterm outcome\n",
    "gb_preterm = models.build_gbdt()\n",
    "models.fit_gbdt(gb_preterm, xtrain, ytrain_preterm, xval, yval_preterm)\n",
    "models.save_pickle(gb_preterm, 'models/gb_preterm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704797047970479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9480    0.9944    0.9706       532\n",
      "        True     0.9943    0.9475    0.9703       552\n",
      "\n",
      "    accuracy                         0.9705      1084\n",
      "   macro avg     0.9712    0.9709    0.9705      1084\n",
      "weighted avg     0.9716    0.9705    0.9705      1084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example loading model to evaluate\n",
    "del gb_preterm\n",
    "gb_preterm = models.load_pickle('models/gb_preterm')\n",
    "print(gb_preterm.score(xtest, ytest_preterm))\n",
    "print(sklearn.metrics.classification_report(ytest_preterm, gb_preterm.predict(xtest), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 2s 20ms/step - loss: 1.1372 - accuracy: 0.0000e+00 - auc: 0.5205 - val_loss: 0.5655 - val_accuracy: 0.0000e+00 - val_auc: 0.8136\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.7376 - accuracy: 0.0000e+00 - auc: 0.6227 - val_loss: 0.4533 - val_accuracy: 0.0000e+00 - val_auc: 0.8745\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6094 - accuracy: 0.0000e+00 - auc: 0.7466 - val_loss: 0.3692 - val_accuracy: 0.0000e+00 - val_auc: 0.9297\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.0000e+00 - auc: 0.8493 - val_loss: 0.3468 - val_accuracy: 0.0000e+00 - val_auc: 0.9602\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.0000e+00 - auc: 0.8946 - val_loss: 0.2316 - val_accuracy: 0.0000e+00 - val_auc: 0.9782\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.0000e+00 - auc: 0.9324 - val_loss: 0.1911 - val_accuracy: 0.0000e+00 - val_auc: 0.9852\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.2718 - accuracy: 0.0000e+00 - auc: 0.9550 - val_loss: 0.1652 - val_accuracy: 0.0000e+00 - val_auc: 0.9870\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2541 - accuracy: 0.0000e+00 - auc: 0.9610 - val_loss: 0.1462 - val_accuracy: 0.0000e+00 - val_auc: 0.9902\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.2158 - accuracy: 0.0000e+00 - auc: 0.9717 - val_loss: 0.1383 - val_accuracy: 0.0000e+00 - val_auc: 0.9926\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1973 - accuracy: 0.0000e+00 - auc: 0.9758 - val_loss: 0.1347 - val_accuracy: 0.0000e+00 - val_auc: 0.9926\n",
      "INFO:tensorflow:Assets written to: models/selu_preterm/assets\n"
     ]
    }
   ],
   "source": [
    "# Let's work on NN2 first. Once we have that, it will be easy to simplify it back to NN1.\n",
    "\n",
    "# Example with the preterm outcome\n",
    "selu_preterm = models.build_NN_selu(input_len=xtest.shape[1])  # Assuming xtest is (batch, cols)\n",
    "history = models.fit_NN_selu(selu_preterm, xtrain, ytrain_preterm, xval, yval_preterm)\n",
    "models.save_NN(selu_preterm, 'models/selu_preterm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.0000e+00 - auc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.12338992953300476, 0.0, 0.9925220608711243]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example loading model to evaluate\n",
    "del selu_preterm\n",
    "selu_preterm = models.load_NN('models/selu_preterm')\n",
    "selu_preterm.evaluate(xtest, ytest_preterm)  # Output is [loss, accuracy, auc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "b61fea741fbe03daed72c4da298e8e8eaab54de8e50b0bc374a5b705e2fb6e53"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}